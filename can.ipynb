{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"SR2I208.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1kQcr0AWbVW19lgmQXtmCvO5-thzYjfyG\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "\"\"\"# **Preprocessing des donnÃ©es:**\"\"\"\n",
    "\n",
    "def read_data_SubClass(data) :\n",
    "    \n",
    "  #data = pd.read_csv(file_data)\n",
    "  data = data.dropna()\n",
    "\n",
    "  data[\"Data\"].astype(str)\n",
    "  data[\"Data\"] = data[\"Data\"].str.replace(\" \" , \"\")\n",
    "  data[\"Data\"] = data[\"Data\"].apply(int , base = 16)\n",
    "\n",
    "  data[\"Class\"].replace(['Normal', 'Attack'],\n",
    "                        [0, 1], inplace=True)\n",
    "  \n",
    "  uniques = data[\"SubClass\"].unique()\n",
    "  data[\"SubClass\"].replace(uniques , [i for i in range(len(uniques))] , inplace = True)\n",
    "\n",
    "  uniques_2 = data[\"SubClass\"].unique()\n",
    "  data[\"SubClass\"].replace(uniques_2 , [i for i in range(len(uniques_2))] , inplace = True)\n",
    "\n",
    "  data[\"Arbitration_ID\"]  =  data[\"Arbitration_ID\"].apply(int , base = 16)\n",
    "\n",
    "  X = data[['Timestamp' ,'Arbitration_ID', 'DLC','Data']].values\n",
    "  y = data[\"SubClass\"].values\n",
    "  \n",
    "  return X , y\n",
    "\n",
    "def read_data(data) :\n",
    "    \n",
    "  #data = pd.read_csv(file_data)\n",
    "  data = data.dropna()\n",
    "\n",
    "  data[\"Data\"].astype(str)\n",
    "  data[\"Data\"] = data[\"Data\"].str.replace(\" \" , \"\")\n",
    "  data[\"Data\"] = data[\"Data\"].apply(int , base = 16)\n",
    "\n",
    "    \n",
    "  data[\"Class\"].replace(['Normal', 'Attack'],\n",
    "                        [0, 1], inplace=True)\n",
    "\n",
    "\n",
    "  data[\"Arbitration_ID\"]  =  data[\"Arbitration_ID\"].apply(int , base = 16)\n",
    "\n",
    "  X = data[['Timestamp' ,'Arbitration_ID', 'DLC','Data']].values\n",
    "  y = data[\"Class\"].values\n",
    "\n",
    "  return X , y\n",
    "\n",
    "# donnÃ©es de test :\n",
    "list_test = ['Pre_submit_S.csv' , 'Pre_submit_D.csv', 'Fin_host_session_submit_S.csv']\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "for elt in list_test : \n",
    "    df = pd.read_csv(elt)\n",
    "    frames = [df_test , df]\n",
    "    df_test = pd.concat(frames)\n",
    "\n",
    "list_train = ['Pre_train_D_1.csv' , 'Pre_train_S_1.csv' , 'Pre_train_S_2.csv', 'Pre_train_D_2.csv']\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "\n",
    "for elt in list_train : \n",
    "    df = pd.read_csv(elt)\n",
    "    frames = [df_train , df]\n",
    "    df_train = pd.concat(frames)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "\"\"\"#**Distribution de data dans les diffÃ©rents fichiers**\"\"\"\n",
    "\n",
    "list_of_csv = ['Pre_train_D_0.csv' , 'Pre_train_D_1.csv' , 'Pre_train_D_2.csv' , 'Pre_train_S_0.csv' , 'Pre_train_S_1.csv' , 'Pre_train_S_2.csv']\n",
    "\n",
    "print(\"Preliminary , training\")\n",
    "y_tot = 0\n",
    "y_normal = 0\n",
    "y_attack = 0\n",
    "for elt in list_of_csv :\n",
    "  data = pd.read_csv(elt)\n",
    "  _ , y = read_data(data) \n",
    "  n = len(y)\n",
    "  y_tot += n\n",
    "  print(\"Number of data points in \" , elt ,\" : \" ,len(y))\n",
    "  for i in np.unique(y) :\n",
    "      print(i , list(y).count(i) )\n",
    "      y_normal += (1-i)*list(y).count(i)\n",
    "      y_attack += i*list(y).count(i)\n",
    "\n",
    "  print(\"         --------**---------\")\n",
    "\n",
    "print(\"The total number of data points :\" , y_tot)\n",
    "print(\"Normal : \" , y_normal)\n",
    "print(\"Attack : \" , y_attack)\n",
    "\n",
    "print(\"Preliminary , submission\")\n",
    "y_tot = 0\n",
    "y_normal = 0\n",
    "y_attack = 0\n",
    "\n",
    "for elt in ['Pre_submit_D.csv','Pre_submit_S.csv'] :\n",
    "  data = pd.read_csv(elt)\n",
    "  _ , y = read_data(data) \n",
    "  n = len(y)\n",
    "  y_tot += n\n",
    "  print(\"Number of data points in \" , elt ,\" : \" ,len(y))\n",
    "  for i in np.unique(y) :\n",
    "      print(i , list(y).count(i) )\n",
    "      y_normal += (1-i)*list(y).count(i)\n",
    "      y_attack += i*list(y).count(i)\n",
    "  print(\"         --------**---------\")\n",
    "\n",
    "print(\"The total number of data points :\" , y_tot)\n",
    "print(\"Normal : \" , y_normal)\n",
    "print(\"Attack : \" , y_attack)\n",
    "\n",
    "data = pd.read_csv('Fin_host_session_submit_S.csv')\n",
    "\n",
    "print(\"Final\")\n",
    "_ , y = read_data(data) \n",
    "n = len(y)\n",
    "\n",
    "print(\"Number of data points in \" , \"Fin_host_session_submit_S.csv\" ,\" : \" ,len(y))\n",
    "for i in np.unique(y) :\n",
    "  print(i , list(y).count(i) )\n",
    "\n",
    "\"\"\"# **2 classes:**\"\"\"\n",
    "\n",
    "# des dictionnaires pour garder les scores et valeurs de f1 des diffÃ©rents algorithmes\n",
    "dict_of_scores = {}\n",
    "dict_of_f1 = {}\n",
    "\n",
    "df_train.isnull().sum()\n",
    "\n",
    "df_test.isnull().sum()\n",
    "\n",
    "X_test , y_test = read_data(df_test)\n",
    "X_train , y_train = read_data(df_train)\n",
    "\n",
    "Counter(y_test)\n",
    "\n",
    "Counter(y_train)\n",
    "\n",
    "figure, axis = plt.subplots(1,2)\n",
    "i=0\n",
    "lab = 'train'\n",
    "\n",
    "for elt in [y_train, y_test] :\n",
    "   ratio = Counter(elt)\n",
    "   labels = list(ratio.keys())\n",
    "   sizes = list(ratio.values())\n",
    "   \n",
    "   axis[i].pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "   axis[i].axis('equal')\n",
    "   \n",
    "   axis[i].set_title( 'Distribution in '+ lab + ' data' )\n",
    "   lab= 'test'\n",
    "   i+=1\n",
    "\n",
    "plt.show()\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=1)\n",
    "X_test, y_test = undersample.fit_resample(X_test, y_test)\n",
    "\n",
    "X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\"\"\"#**KMeans avec 2 classes**\"\"\"\n",
    "\n",
    "X = sc.fit_transform(X_test)\n",
    "y = y_test\n",
    "\n",
    "Counter(y)\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "model = KMeans(n_clusters = 2)\n",
    "\n",
    "model.fit(X)\n",
    "\n",
    "centers = model.cluster_centers_\n",
    "\n",
    "plt.scatter(centers[:, 0], centers[:, 1], s=100, c='black')\n",
    "\n",
    "labels = model.labels_\n",
    "\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1], c= labels, cmap='cool' )\n",
    "sns.scatterplot(x=centers[:,0], y=centers[:,1],  cmap='black' )\n",
    "\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1],marker='o' ,c= y, cmap='cool' )\n",
    "\n",
    "for s in np.unique(y) :\n",
    "  print('Number of predicted in cluster' , s )\n",
    "  print(s , np.sum(labels == s) )\n",
    "\n",
    "for s in np.unique(y) :\n",
    "  print('Real distribution of messages predicted as ' , s )\n",
    "  #real labels of messages predicted as of label s\n",
    "  real_of_predicted = y[labels == s]\n",
    "  for i in np.unique(real_of_predicted) :\n",
    "    print(i , np.sum(real_of_predicted == i) )\n",
    "\n",
    "accuracy = accuracy_score(y, labels)\n",
    "f1 = f1_score(y , labels)\n",
    "\n",
    "print(\"Accuracy=\", accuracy, \"  f1=\", f1)\n",
    "\n",
    "dict_of_scores['k_means'] = accuracy\n",
    "dict_of_f1['k_means'] = f1\n",
    "\n",
    "\"\"\"# **K-NN et Decision Trees pour 2 classes**\"\"\"\n",
    "\n",
    "Counter(y_train)\n",
    "\n",
    "k_values= [3, 5, 7, 9]\n",
    "for k in k_values :\n",
    "  model = KNeighborsClassifier(n_neighbors= k)\n",
    "  model.fit(X_train, y_train)\n",
    "  y_pred = model.predict(X_test)\n",
    "  f1 = f1_score(y_test , y_pred , average='binary')\n",
    "\n",
    "  print(\"Accuracy for k=\", k , \"is: \", accuracy_score(y_test, y_pred))\n",
    "  print(\"Confusion matrix: \" , confusion_matrix(y_test, y_pred))\n",
    "  print(\"f1: \" , f1)\n",
    "  print(\"=================***====================\")\n",
    "\n",
    "\"\"\"**La meilleure valeur de k est k = 3.**\"\"\"\n",
    "\n",
    "models = [ KNeighborsClassifier(n_neighbors=3), DecisionTreeClassifier()]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test , y_pred , average='binary')\n",
    "\n",
    "    dict_of_scores[str(model)] = score\n",
    "    dict_of_f1[str(model)] = f1\n",
    "\n",
    "    print(\"Accuracy of\" , model , \"is: \", score)\n",
    "    print(\"F1 score of\" , model , \"is: \", f1)\n",
    "    conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "    print(\"Confusion Matrix:\\n\",conf_matrix)\n",
    "    print(\"\\n==============***===============\")\n",
    "\n",
    "\"\"\"## **Courbe des scores et des valeurs de f1 pour les diffÃ©rents algorithmes**\"\"\"\n",
    "\n",
    "models_ = list(dict_of_scores.keys())\n",
    "accuracies = list(dict_of_scores.values())\n",
    "f1s = list(dict_of_f1.values())\n",
    "\n",
    "plt.plot(models_ , accuracies , color = 'r' , label='Accuracy')\n",
    "plt.plot(models_ , f1s , color = 'black' , label='f1 score')\n",
    "plt.title(\"Comparaison des résultats des differents modeles\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"# **Classification en 5 classes: normal et les 4 attaques**\"\"\"\n",
    "\n",
    "Xm_test , ym_test = read_data_SubClass(df_test)\n",
    "Xm_train , ym_train = read_data_SubClass(df_train)\n",
    "\n",
    "Counter(ym_test)\n",
    "\n",
    "Counter(ym_train)\n",
    "\n",
    "figure, axis = plt.subplots(1,2)\n",
    "i=0\n",
    "lab = 'train'\n",
    "\n",
    "for elt in [ym_train, ym_test] :\n",
    "   ratio = Counter(elt)\n",
    "   labels = list(ratio.keys())[1:]\n",
    "   sizes = list(ratio.values())[1:]\n",
    "   \n",
    "   axis[i].pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "   axis[i].axis('equal')\n",
    "   \n",
    "   axis[i].set_title( 'Attacks in '+ lab + ' data' )\n",
    "   lab= 'test'\n",
    "   i+=1\n",
    "\n",
    "plt.show()\n",
    "\n",
    "sc = StandardScaler()\n",
    "Xm_train = sc.fit_transform(Xm_train)\n",
    "Xm_test = sc.transform(Xm_test)\n",
    "\n",
    "dict_scores = {}\n",
    "dict_f1s = {}\n",
    "\n",
    "\"\"\"#**KMeans avec 5 classes**\"\"\"\n",
    "\n",
    "Xm = sc.fit_transform(Xm_test)\n",
    "ym = ym_test\n",
    "\n",
    "Counter(ym)\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "Xm = pca.fit_transform(Xm)\n",
    "\n",
    "model = KMeans(n_clusters = 5)\n",
    "\n",
    "model.fit(Xm)\n",
    "\n",
    "centers = model.cluster_centers_\n",
    "\n",
    "plt.scatter(centers[:, 0], centers[:, 1], s=100, c='black')\n",
    "\n",
    "labels = model.labels_\n",
    "\n",
    "sns.scatterplot(x=Xm[:,0], y=Xm[:,1], c= labels, cmap='cool' )\n",
    "sns.scatterplot(x=centers[:,0], y=centers[:,1],  cmap='black' )\n",
    "\n",
    "sns.scatterplot(x=Xm[:,0], y=Xm[:,1],marker='o' ,c= ym, cmap='cool' )\n",
    "\n",
    "for s in np.unique(ym) :\n",
    "  print('Number of predicted in cluster' , s )\n",
    "  print(s , np.sum(labels == s) )\n",
    "\n",
    "for s in np.unique(ym) :\n",
    "  print('Real distribution of messages predicted as ' , s )\n",
    "  #real labels of messages predicted as of label s\n",
    "  real_of_predicted = ym[labels == s]\n",
    "  for i in np.unique(real_of_predicted) :\n",
    "    print(i , np.sum(real_of_predicted == i) )\n",
    "\n",
    "labels\n",
    "\n",
    "# On va donner Ã  chaque cluster le label majoritaire : \n",
    "for i in range(len(labels)) : \n",
    "  \n",
    "  if labels[i] == 1 :\n",
    "    labels[i] = 3\n",
    "  elif labels[i] == 2 :\n",
    "    labels[i] = 4\n",
    "  elif labels[i] == 3 :\n",
    "    labels[i] = 2\n",
    "  elif labels[i] == 4 :\n",
    "    labels[i] = 1\n",
    "\n",
    "labels\n",
    "\n",
    "accuracy = accuracy_score(ym, labels)\n",
    "f1 = f1_score(ym , labels,average=None)\n",
    "\n",
    "print(\"Accuracy=\", accuracy, \"  f1=\", f1)\n",
    "\n",
    "dict_scores['K-means'] = accuracy\n",
    "dict_f1s['Kmeans'] = f1\n",
    "\n",
    "\"\"\"# **K-NN et Decision Trees pour 5 classes**\"\"\"\n",
    "\n",
    "models = [KNeighborsClassifier(n_neighbors=3)  , DecisionTreeClassifier()]\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    model.fit(Xm_train,ym_train)\n",
    "    y_pred = model.predict(Xm_test)\n",
    "    score = accuracy_score(ym_test, y_pred)\n",
    "    f1 = f1_score(ym_test , y_pred , average=None)\n",
    "    conf_matrix = confusion_matrix(ym_test,y_pred)\n",
    "\n",
    "    dict_scores[str(model)] = score\n",
    "    dict_f1s[str(model)] = f1\n",
    "\n",
    "    print(\"Accuracy of\" , model , \"is: \", score)\n",
    "    print(\"F1 score of\" , model , \"is: \", f1)\n",
    "    print(\"Confusion Matrix:\\n\",conf_matrix)\n",
    "    print(\"\\n==============***===============\")\n",
    "\n",
    "models_ = list(dict_scores.keys())\n",
    "accuracies = list(dict_scores.values())\n",
    "f1s = list(dict_f1s.values())\n",
    "colors_f1s = ['black' , 'b' , 'g' , 'y', 'm']\n",
    "plt.plot(models_ , accuracies , color = 'r' , label='Accuracy')\n",
    "for i in range(4) :\n",
    "  plt.plot(models_ , [elt[i] for elt in f1s] , color = colors_f1s[i] , label=str('f1 score of '+str(i))\n",
    "\n",
    "plt.title(\"Comparaison des résultats des différents modeles\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
